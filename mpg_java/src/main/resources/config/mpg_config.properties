# number of threads used in the system, if value <=0, then (#available_processors + 1) is used
thread_pool_size=0
# the precision of double values in this system
value_precision=1e-8
# which implementation of MinimaxSolver to use, now we have the MinimaxSolverGurobiImpl or MinimaxSolverLpSolveImpl
minimax_solver_class=edu.uic.cs.purposeful.mpg.minimax_solver.impl.MinimaxSolverGurobiImpl
# which implementation of MinimaxSolver to try again when "minimax_solver_class" fails
minimax_solver_class_backup=edu.uic.cs.purposeful.mpg.minimax_solver.impl.MinimaxSolverLpSolveImpl
# value for artificial bias feature, ignored if this value < 0
bias_feature_value=1
# whether regularize bias feature if the above bias feature is added
regularize_bias_feature=true
# whether expand features by using their quadratic combinations: features + (features * features)
# note currently this feature is NOT available for 'binary' and 'linear-chain' data sets
feature_quadratic_expansion=false
# if we use feature quadratic expansion, the number of features could not be too large, this is the max number allowed
max_num_of_features_for_quadratic_expansion=100
# whether use Logistic Regression to learn initial theta values
learn_initial_thetas=false
# when using Logistic Regression (LibLinear), the stopping criterion
logistic_regression_stopping_criterion=0.001
# double oracle method stops when either of the two players reaches this number of permutations;
# if this value <= 0, the double oracle optimizer continue runs until converge (maybe exponential...)
max_num_of_double_oracle_permutations=300
# the max length of feature vector to display, since some vector could be very very huge
max_display_vector_length=1000

# the implementation of numerical optimizer, comment out any one below
# numerical_optimizer_implementation=edu.uic.cs.purposeful.mpg.optimizer.numerical.lbfgs.StanfordLBFGSWrapper
# numerical_optimizer_implementation=edu.uic.cs.purposeful.mpg.optimizer.numerical.lbfgs.RosiLBFGSWrapper
numerical_optimizer_implementation=edu.uic.cs.purposeful.mpg.optimizer.numerical.adadelta.JhuAdaDeltaWrapper

# the terminate accuracy with which the solution is to be found
lbfgs_terminate_gradient_tolerance=1e-6
lbfgs_terminate_value_tolerance=1e-16
lbfgs_max_number_of_iterations=200

# rho value for adadelta
adadelta_decay_rate=0.95
# epsilon value for adadelta (=exp(-6))
adadelta_smoothing_constant_addend=0.00247875217
adadelta_terminate_gradient_tolerance=1e-6
# whether use value as termination criterion
adadelta_use_terminate_value=true
adadelta_terminate_value_tolerance=1e-4
adadelta_number_of_iterations=200

# whether show the running tracing in the console or not
show_running_tracing=true
